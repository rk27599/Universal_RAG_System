# System Architecture

This document provides a comprehensive overview of the Universal RAG System's architecture, design decisions, and component interactions.

## ðŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Universal RAG System                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Web Scraper â”‚â”€â”€â”€â–¶â”‚ RAG System   â”‚â”€â”€â”€â–¶â”‚ Text Generator  â”‚     â”‚
â”‚  â”‚             â”‚    â”‚              â”‚    â”‚ (Ollama)        â”‚     â”‚
â”‚  â”‚ â€¢ Async     â”‚    â”‚ â€¢ Retrieval  â”‚    â”‚ â€¢ Local LLMs    â”‚     â”‚
â”‚  â”‚ â€¢ Sync      â”‚    â”‚ â€¢ Caching    â”‚    â”‚ â€¢ API Interface â”‚     â”‚
â”‚  â”‚ â€¢ Metadata  â”‚    â”‚ â€¢ Indexing   â”‚    â”‚ â€¢ Model Mgmt    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                   â”‚                      â”‚            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Data Store  â”‚    â”‚ Vector Index â”‚    â”‚ Query Processor â”‚     â”‚
â”‚  â”‚             â”‚    â”‚              â”‚    â”‚                 â”‚     â”‚
â”‚  â”‚ â€¢ JSON      â”‚    â”‚ â€¢ TF-IDF     â”‚    â”‚ â€¢ Enhancement   â”‚     â”‚
â”‚  â”‚ â€¢ Cache     â”‚    â”‚ â€¢ Trigrams   â”‚    â”‚ â€¢ Context Build â”‚     â”‚
â”‚  â”‚ â€¢ Metadata  â”‚    â”‚ â€¢ Scoring    â”‚    â”‚ â€¢ Result Rank   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ“¦ Core Components

### 1. Web Scraping Layer

#### Synchronous Web Scraper (`web_scraper.py`)
- **Purpose**: Reliable, debuggable web scraping
- **Features**: Structure preservation, robots.txt compliance, content extraction
- **Use Case**: Development, testing, small-scale scraping

#### Asynchronous Web Scraper (`async_web_scraper.py`)
- **Purpose**: High-performance concurrent scraping
- **Features**: Async I/O, connection pooling, rate limiting
- **Use Case**: Production, large-scale scraping, performance-critical applications

```python
# Architecture Flow
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Request   â”‚â”€â”€â”€â–¶â”‚  Response   â”‚â”€â”€â”€â–¶â”‚  Extract    â”‚
â”‚   Queue     â”‚    â”‚  Handler    â”‚    â”‚  Content    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Rate Limit  â”‚    â”‚   Cache     â”‚    â”‚  Metadata   â”‚
â”‚ Manager     â”‚    â”‚  Manager    â”‚    â”‚  Enricher   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Key Design Decisions

**Structure Preservation**:
- Maintains HTML hierarchy (h1 â†’ h2 â†’ h3)
- Preserves semantic relationships between content
- Enables context-aware chunking

**Metadata Enrichment**:
- Page titles and section hierarchies
- Content types (heading, paragraph, code, list)
- Domain and URL information
- Timestamp and caching metadata

### 2. RAG Processing Layer

#### Document Processing Pipeline

```
Raw HTML â†’ Content Extract â†’ Semantic Chunk â†’ Index Build â†’ Query Ready
    â”‚             â”‚              â”‚              â”‚            â”‚
   DOM         Sections      Hierarchical    TF-IDF       Vector
  Parse         + Meta       Chunks + Meta   Vectors       Store
```

#### Retrieval System Architecture

```python
# TF-IDF Enhancement Pipeline
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Query     â”‚â”€â”€â”€â–¶â”‚  Enhance    â”‚â”€â”€â”€â–¶â”‚  Vectorize  â”‚
â”‚ Processing  â”‚    â”‚   Terms     â”‚    â”‚   Query     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Similarity â”‚    â”‚  Metadata   â”‚    â”‚   Rank &    â”‚
â”‚ Computation â”‚    â”‚   Boost     â”‚    â”‚   Return    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Key Features

**Enhanced TF-IDF**:
- Trigram analysis for better matching
- Sublinear term frequency scaling
- Content type-based score boosting
- Domain-specific relevance tuning

**Intelligent Caching**:
- Content-based cache keys (SHA-256)
- Automatic invalidation strategies
- Memory-efficient storage
- Cross-session persistence

### 3. Generation Layer

#### Ollama Integration Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Retrieved  â”‚â”€â”€â”€â–¶â”‚   Context   â”‚â”€â”€â”€â–¶â”‚   Ollama    â”‚
â”‚   Chunks    â”‚    â”‚   Builder   â”‚    â”‚    API      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Metadata   â”‚    â”‚   Prompt    â”‚    â”‚  Response   â”‚
â”‚ Filtering   â”‚    â”‚ Template    â”‚    â”‚ Processing  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Local LLM Benefits
- **Privacy**: No data sent to external services
- **Speed**: Local processing eliminates network latency
- **Cost**: No per-request API charges
- **Customization**: Full control over model selection and parameters

## ðŸ”„ Data Flow Architecture

### Scraping to Storage Flow

```mermaid
graph TD
    A[Start URLs] --> B[URL Queue]
    B --> C[Fetch Page]
    C --> D[Parse HTML]
    D --> E[Extract Content]
    E --> F[Create Chunks]
    F --> G[Add Metadata]
    G --> H[Store JSON]
    H --> I[Update Cache]

    C --> J[Discover URLs]
    J --> B

    E --> K[Respect robots.txt]
    K --> L[Rate Limiting]
```

### Query Processing Flow

```mermaid
graph TD
    A[User Query] --> B[Query Enhancement]
    B --> C[Vectorize Query]
    C --> D[Compute Similarities]
    D --> E[Apply Boosting]
    E --> F[Rank Results]
    F --> G[Return Top-K]

    G --> H[Demo Mode]
    G --> I[Generation Mode]

    I --> J[Build Context]
    J --> K[Ollama API]
    K --> L[Generate Response]
```

## ðŸ“Š Performance Architecture

### Async Scraping Performance

```python
# Concurrent Processing Model
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Main Thread   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Async    â”‚  â”‚â”€â”€â”
â”‚  â”‚  Event    â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚   Loop    â”‚  â”‚  â”œâ”€â–¶â”‚  Worker 1   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”œâ”€â–¶â”‚  Worker 2   â”‚
                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â””â”€â–¶â”‚  Worker N   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Performance Optimizations

**Connection Management**:
- Session pooling for connection reuse
- Configurable connection limits
- Automatic connection cleanup

**Memory Management**:
- Streaming content processing
- Garbage collection optimization
- Memory usage monitoring

**Caching Strategy**:
- Multi-level caching (memory + disk)
- Content-based cache keys
- Intelligent cache invalidation

### Retrieval Performance

#### TF-IDF Optimization

```python
# Vectorization Pipeline
Text â†’ Tokenize â†’ N-grams â†’ TF â†’ IDF â†’ Vector
  â”‚        â”‚         â”‚      â”‚     â”‚      â”‚
Clean   Split     Build   Count  Calc   Norm
Text    Terms    Grams   Freq   Weight  Vector
```

**Performance Characteristics**:
- **Indexing**: O(nÃ—m) where n=documents, m=average terms
- **Query**: O(kÃ—m) where k=query terms, m=vocabulary size
- **Memory**: Linear with vocabulary size and document count

#### Scoring Algorithm

```python
def enhanced_similarity_score(query_vector, doc_vector, metadata):
    # Base TF-IDF similarity
    base_score = cosine_similarity(query_vector, doc_vector)

    # Content type boosting
    content_boost = get_content_boost(metadata['content_type'])

    # Section hierarchy boost
    hierarchy_boost = get_hierarchy_boost(metadata['section_hierarchy'])

    # Final enhanced score
    return base_score * content_boost * hierarchy_boost
```

## ðŸ› ï¸ Design Patterns

### 1. Strategy Pattern - Multiple Scrapers

```python
class ScrapingStrategy:
    def scrape(self, urls: List[str]) -> bool:
        raise NotImplementedError

class AsyncScrapingStrategy(ScrapingStrategy):
    def scrape(self, urls: List[str]) -> bool:
        return asyncio.run(self._async_scrape(urls))

class SyncScrapingStrategy(ScrapingStrategy):
    def scrape(self, urls: List[str]) -> bool:
        return self._sync_scrape(urls)
```

### 2. Factory Pattern - Content Extractors

```python
class ContentExtractorFactory:
    @staticmethod
    def get_extractor(content_type: str) -> ContentExtractor:
        if content_type == 'documentation':
            return DocumentationExtractor()
        elif content_type == 'blog':
            return BlogExtractor()
        else:
            return GenericExtractor()
```

### 3. Observer Pattern - Progress Tracking

```python
class ScrapingObserver:
    def on_page_scraped(self, url: str, success: bool):
        pass

class ProgressTracker(ScrapingObserver):
    def on_page_scraped(self, url: str, success: bool):
        self.update_progress(url, success)
```

## ðŸš€ Scalability Considerations

### Horizontal Scaling

**Distributed Scraping**:
- URL queue distribution
- Worker node coordination
- Result aggregation
- Load balancing

**Shared Storage**:
- Centralized data store
- Distributed caching
- Consistent metadata
- Conflict resolution

### Vertical Scaling

**Resource Optimization**:
- Memory usage profiling
- CPU utilization monitoring
- I/O bottleneck identification
- Performance tuning

**Capacity Planning**:
- Growth projection models
- Resource requirement estimation
- Performance degradation thresholds
- Scaling trigger points

## ðŸ”’ Security Architecture

### Web Scraping Security

**Respectful Crawling**:
- robots.txt compliance
- Rate limiting enforcement
- User-agent identification
- Session management

**Data Protection**:
- Secure data storage
- Access control mechanisms
- Data retention policies
- Privacy compliance

### API Security

**Local LLM Security**:
- Network isolation
- Access control
- Model validation
- Resource limits

## ðŸ“ˆ Monitoring & Observability

### Performance Metrics

```python
@dataclass
class SystemMetrics:
    scraping_performance: ScrapingMetrics
    retrieval_performance: RetrievalMetrics
    generation_performance: GenerationMetrics
    system_resources: ResourceMetrics
```

### Health Checks

- **Scraping Health**: Success rates, error patterns
- **Retrieval Health**: Query performance, result quality
- **Generation Health**: API availability, response times
- **System Health**: Resource usage, error rates

## ðŸ”® Future Architecture Considerations

### Planned Enhancements

1. **Multi-modal Support**: Images, PDFs, videos
2. **Advanced Retrieval**: Semantic embeddings, hybrid search
3. **Distributed Processing**: Multi-node coordination
4. **Real-time Updates**: Change detection, incremental updates

### Technology Evolution

- **Vector Databases**: Integration with specialized vector stores
- **Advanced LLMs**: Support for larger, more capable models
- **Edge Computing**: Deployment to edge environments
- **Cloud Integration**: Hybrid cloud-local architectures

---

This architecture provides a solid foundation for scalable, performant, and maintainable RAG systems while maintaining flexibility for future enhancements.